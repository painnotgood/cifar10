{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NL460H809-o3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "029a75da-c2e6-46c8-add9-87f89e7c4d85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import resnet34\n",
        "import torchvision.datasets\n",
        "import numpy as np\n",
        "\n",
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "num_epochs = 10\n",
        "lr = 0.1\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "num_classes = 10"
      ],
      "metadata": {
        "id": "LXd8Bgxizl4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomApply([\n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2)\n",
        "    ], p=0.7),\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
        "    transforms.RandomApply([\n",
        "        transforms.RandomGrayscale(p=1.0)\n",
        "    ], p=0.25),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
        "                         (0.2023, 0.1994, 0.2010)),\n",
        "    transforms.RandomErasing(p=0.25, scale=(0.02, 0.1))\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
        "                         (0.2470, 0.2435, 0.2616)),\n",
        "])"
      ],
      "metadata": {
        "id": "OUSLQmF4z42l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform_train)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform_test)\n",
        "val_ratio = 0.1\n",
        "train_size = int((1 - val_ratio) * len(trainset))\n",
        "val_size = len(trainset) - train_size"
      ],
      "metadata": {
        "id": "KVzgMhys1La8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70ce178b-be6a-4289-8bb2-b5427f8627d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:04<00:00, 42.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=10, min_delta=0.0):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.best_loss = float('inf')\n",
        "        self.early_stop = False\n",
        "        self.best_model_state = None\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "        if val_loss < self.best_loss - self.min_delta:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0\n",
        "            self.best_model_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "\n",
        "    def restore_best_model(self, model):\n",
        "        if self.best_model_state is not None:\n",
        "            model.load_state_dict(self.best_model_state)\n"
      ],
      "metadata": {
        "id": "fAKV-02_3O7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(restart_seed=None):\n",
        "    if restart_seed is not None:\n",
        "        torch.manual_seed(restart_seed)\n",
        "\n",
        "    train_subset, val_subset = random_split(trainset, [train_size, val_size])\n",
        "    trainloader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
        "    valloader = DataLoader(val_subset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
        "    testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
        "    model = resnet34(weights=None)\n",
        "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "    model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "    model.maxpool = nn.Identity()\n",
        "    model = model.to(device)\n",
        "\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
        "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "    early_stopper = EarlyStopping(patience=10, min_delta=0.001)\n",
        "\n",
        "    scaler = torch.amp.GradScaler(\"cuda\")\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        for inputs, targets in trainloader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            with torch.amp.autocast(\"cuda\"):\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, targets)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            optimizer.zero_grad()\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for inputs, targets in valloader:\n",
        "                inputs, targets = inputs.to(device), targets.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, targets)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "        val_loss /= len(valloader)\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs} - Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "        early_stopper(val_loss, model)\n",
        "        if early_stopper.early_stop:\n",
        "            early_stopper.restore_best_model(model)\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "55D0bx8W59FD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnt = 10\n",
        "num_epochs = 5\n",
        "for i in range(cnt):\n",
        "    lr = 10**np.random.uniform(-2, -1)\n",
        "    print(f\"\\nTrial {i+1}/{cnt} — Testing learning rate: {lr:.6f}\")\n",
        "    train_model(restart_seed=100 + i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsk-4CLqo7uU",
        "outputId": "55ccc5bd-0228-487a-d1b7-56e29a05ef1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial 1/10 — Testing learning rate: 0.034092\n",
            "Epoch 1/5 - Val Loss: 1.7926\n",
            "Epoch 2/5 - Val Loss: 1.5885\n",
            "Epoch 3/5 - Val Loss: 1.4899\n",
            "Epoch 4/5 - Val Loss: 1.1568\n",
            "Epoch 5/5 - Val Loss: 1.0573\n",
            "\n",
            "Trial 2/10 — Testing learning rate: 0.021645\n",
            "Epoch 1/5 - Val Loss: 6.7041\n",
            "Epoch 2/5 - Val Loss: 1.4343\n",
            "Epoch 3/5 - Val Loss: 1.3255\n",
            "Epoch 4/5 - Val Loss: 1.1984\n",
            "Epoch 5/5 - Val Loss: 1.0743\n",
            "\n",
            "Trial 3/10 — Testing learning rate: 0.015041\n",
            "Epoch 1/5 - Val Loss: 1.8403\n",
            "Epoch 2/5 - Val Loss: 1.5076\n",
            "Epoch 3/5 - Val Loss: 1.3079\n",
            "Epoch 4/5 - Val Loss: 1.1724\n",
            "Epoch 5/5 - Val Loss: 1.0846\n",
            "\n",
            "Trial 4/10 — Testing learning rate: 0.044454\n",
            "Epoch 1/5 - Val Loss: 1.7491\n",
            "Epoch 2/5 - Val Loss: 4.8845\n",
            "Epoch 3/5 - Val Loss: 1.4124\n",
            "Epoch 4/5 - Val Loss: 1.1544\n",
            "Epoch 5/5 - Val Loss: 1.0681\n",
            "\n",
            "Trial 5/10 — Testing learning rate: 0.018177\n",
            "Epoch 1/5 - Val Loss: 1.6589\n",
            "Epoch 2/5 - Val Loss: 1.5767\n",
            "Epoch 3/5 - Val Loss: 1.3023\n",
            "Epoch 4/5 - Val Loss: 1.1474\n",
            "Epoch 5/5 - Val Loss: 1.0380\n",
            "\n",
            "Trial 6/10 — Testing learning rate: 0.053361\n",
            "Epoch 1/5 - Val Loss: 1.9327\n",
            "Epoch 2/5 - Val Loss: 1.6229\n",
            "Epoch 3/5 - Val Loss: 1.4250\n",
            "Epoch 4/5 - Val Loss: 1.3025\n",
            "Epoch 5/5 - Val Loss: 1.1353\n",
            "\n",
            "Trial 7/10 — Testing learning rate: 0.031491\n",
            "Epoch 1/5 - Val Loss: 1.7875\n",
            "Epoch 2/5 - Val Loss: 1.6777\n",
            "Epoch 3/5 - Val Loss: 1.4102\n",
            "Epoch 4/5 - Val Loss: 1.2150\n",
            "Epoch 5/5 - Val Loss: 1.1082\n",
            "\n",
            "Trial 8/10 — Testing learning rate: 0.023355\n",
            "Epoch 1/5 - Val Loss: 1.6906\n",
            "Epoch 2/5 - Val Loss: 1.6108\n",
            "Epoch 3/5 - Val Loss: 1.3887\n",
            "Epoch 4/5 - Val Loss: 1.1924\n",
            "Epoch 5/5 - Val Loss: 1.1108\n",
            "\n",
            "Trial 9/10 — Testing learning rate: 0.048839\n",
            "Epoch 1/5 - Val Loss: 1.8256\n",
            "Epoch 2/5 - Val Loss: 1.6289\n",
            "Epoch 3/5 - Val Loss: 1.4458\n",
            "Epoch 4/5 - Val Loss: 1.1797\n",
            "Epoch 5/5 - Val Loss: 1.0992\n",
            "\n",
            "Trial 10/10 — Testing learning rate: 0.015064\n",
            "Epoch 1/5 - Val Loss: 1.7516\n",
            "Epoch 2/5 - Val Loss: 1.4607\n",
            "Epoch 3/5 - Val Loss: 1.3299\n",
            "Epoch 4/5 - Val Loss: 1.1764\n",
            "Epoch 5/5 - Val Loss: 1.0878\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_models = 10\n",
        "num_epochs = 100\n",
        "lr = 0.018\n",
        "\n",
        "ensemble = []\n",
        "for i in range(num_models):\n",
        "    print(f\"Training model {i+1}/{num_models}\")\n",
        "    model = train_model(restart_seed=42+i)\n",
        "    ensemble.append(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfvdLfYx6dNI",
        "outputId": "5fdece15-70df-4189-b6d7-39fc4d14f6f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model 1/10\n",
            "Epoch 1/100 - Val Loss: 1.7871\n",
            "Epoch 2/100 - Val Loss: 1.4514\n",
            "Epoch 3/100 - Val Loss: 1.3698\n",
            "Epoch 4/100 - Val Loss: 1.2614\n",
            "Epoch 5/100 - Val Loss: 1.1942\n",
            "Epoch 6/100 - Val Loss: 1.2296\n",
            "Epoch 7/100 - Val Loss: 1.0914\n",
            "Epoch 8/100 - Val Loss: 1.0355\n",
            "Epoch 9/100 - Val Loss: 1.0522\n",
            "Epoch 10/100 - Val Loss: 0.9980\n",
            "Epoch 11/100 - Val Loss: 0.9733\n",
            "Epoch 12/100 - Val Loss: 0.9999\n",
            "Epoch 13/100 - Val Loss: 0.9564\n",
            "Epoch 14/100 - Val Loss: 1.0041\n",
            "Epoch 15/100 - Val Loss: 0.9585\n",
            "Epoch 16/100 - Val Loss: 0.9957\n",
            "Epoch 17/100 - Val Loss: 0.9652\n",
            "Epoch 18/100 - Val Loss: 0.9055\n",
            "Epoch 19/100 - Val Loss: 0.9327\n",
            "Epoch 20/100 - Val Loss: 0.8772\n",
            "Epoch 21/100 - Val Loss: 0.9095\n",
            "Epoch 22/100 - Val Loss: 0.8635\n",
            "Epoch 23/100 - Val Loss: 0.8667\n",
            "Epoch 24/100 - Val Loss: 0.8936\n",
            "Epoch 25/100 - Val Loss: 0.8817\n",
            "Epoch 26/100 - Val Loss: 0.8879\n",
            "Epoch 27/100 - Val Loss: 0.8898\n",
            "Epoch 28/100 - Val Loss: 0.8744\n",
            "Epoch 29/100 - Val Loss: 0.8362\n",
            "Epoch 30/100 - Val Loss: 0.9332\n",
            "Epoch 31/100 - Val Loss: 0.8475\n",
            "Epoch 32/100 - Val Loss: 0.8462\n",
            "Epoch 33/100 - Val Loss: 0.8622\n",
            "Epoch 34/100 - Val Loss: 0.8557\n",
            "Epoch 35/100 - Val Loss: 0.8324\n",
            "Epoch 36/100 - Val Loss: 0.8283\n",
            "Epoch 37/100 - Val Loss: 0.8488\n",
            "Epoch 38/100 - Val Loss: 0.8086\n",
            "Epoch 39/100 - Val Loss: 0.8326\n",
            "Epoch 40/100 - Val Loss: 0.8390\n",
            "Epoch 41/100 - Val Loss: 0.7954\n",
            "Epoch 42/100 - Val Loss: 0.7725\n",
            "Epoch 43/100 - Val Loss: 0.8121\n",
            "Epoch 44/100 - Val Loss: 0.7994\n",
            "Epoch 45/100 - Val Loss: 0.7850\n",
            "Epoch 46/100 - Val Loss: 0.8161\n",
            "Epoch 47/100 - Val Loss: 0.8044\n",
            "Epoch 48/100 - Val Loss: 0.7954\n",
            "Epoch 49/100 - Val Loss: 0.7995\n",
            "Epoch 50/100 - Val Loss: 0.7847\n",
            "Epoch 51/100 - Val Loss: 0.7840\n",
            "Epoch 52/100 - Val Loss: 0.7817\n",
            "Early stopping triggered.\n",
            "Training model 2/10\n",
            "Epoch 1/100 - Val Loss: 2.2901\n",
            "Epoch 2/100 - Val Loss: 1.4890\n",
            "Epoch 3/100 - Val Loss: 1.3724\n",
            "Epoch 4/100 - Val Loss: 1.2289\n",
            "Epoch 5/100 - Val Loss: 1.2807\n",
            "Epoch 6/100 - Val Loss: 1.1694\n",
            "Epoch 7/100 - Val Loss: 1.0985\n",
            "Epoch 8/100 - Val Loss: 1.0414\n",
            "Epoch 9/100 - Val Loss: 1.0312\n",
            "Epoch 10/100 - Val Loss: 0.9849\n",
            "Epoch 11/100 - Val Loss: 0.9893\n",
            "Epoch 12/100 - Val Loss: 1.0032\n",
            "Epoch 13/100 - Val Loss: 0.9381\n",
            "Epoch 14/100 - Val Loss: 1.0070\n",
            "Epoch 15/100 - Val Loss: 1.0073\n",
            "Epoch 16/100 - Val Loss: 0.9381\n",
            "Epoch 17/100 - Val Loss: 1.0042\n",
            "Epoch 18/100 - Val Loss: 0.9199\n",
            "Epoch 19/100 - Val Loss: 0.9230\n",
            "Epoch 20/100 - Val Loss: 0.9150\n",
            "Epoch 21/100 - Val Loss: 0.9045\n",
            "Epoch 22/100 - Val Loss: 0.9455\n",
            "Epoch 23/100 - Val Loss: 0.8815\n",
            "Epoch 24/100 - Val Loss: 0.8661\n",
            "Epoch 25/100 - Val Loss: 0.9141\n",
            "Epoch 26/100 - Val Loss: 0.8649\n",
            "Epoch 27/100 - Val Loss: 0.8710\n",
            "Epoch 28/100 - Val Loss: 0.8659\n",
            "Epoch 29/100 - Val Loss: 0.8858\n",
            "Epoch 30/100 - Val Loss: 0.8433\n",
            "Epoch 31/100 - Val Loss: 0.8731\n",
            "Epoch 32/100 - Val Loss: 0.8635\n",
            "Epoch 33/100 - Val Loss: 0.8495\n",
            "Epoch 34/100 - Val Loss: 0.8501\n",
            "Epoch 35/100 - Val Loss: 0.8868\n",
            "Epoch 36/100 - Val Loss: 0.8662\n",
            "Epoch 37/100 - Val Loss: 0.7924\n",
            "Epoch 38/100 - Val Loss: 0.8058\n",
            "Epoch 39/100 - Val Loss: 0.8239\n",
            "Epoch 40/100 - Val Loss: 0.8217\n",
            "Epoch 41/100 - Val Loss: 0.8059\n",
            "Epoch 42/100 - Val Loss: 0.8337\n",
            "Epoch 43/100 - Val Loss: 0.8168\n",
            "Epoch 44/100 - Val Loss: 0.8083\n",
            "Epoch 45/100 - Val Loss: 0.8593\n",
            "Epoch 46/100 - Val Loss: 0.8346\n",
            "Epoch 47/100 - Val Loss: 0.9161\n",
            "Early stopping triggered.\n",
            "Training model 3/10\n",
            "Epoch 1/100 - Val Loss: 1.6723\n",
            "Epoch 2/100 - Val Loss: 1.4387\n",
            "Epoch 3/100 - Val Loss: 1.3852\n",
            "Epoch 4/100 - Val Loss: 1.2209\n",
            "Epoch 5/100 - Val Loss: 1.1992\n",
            "Epoch 6/100 - Val Loss: 1.0962\n",
            "Epoch 7/100 - Val Loss: 1.0930\n",
            "Epoch 8/100 - Val Loss: 1.1083\n",
            "Epoch 9/100 - Val Loss: 1.0211\n",
            "Epoch 10/100 - Val Loss: 1.0250\n",
            "Epoch 11/100 - Val Loss: 0.9735\n",
            "Epoch 12/100 - Val Loss: 1.0449\n",
            "Epoch 13/100 - Val Loss: 0.9508\n",
            "Epoch 14/100 - Val Loss: 0.9614\n",
            "Epoch 15/100 - Val Loss: 0.9938\n",
            "Epoch 16/100 - Val Loss: 0.9653\n",
            "Epoch 17/100 - Val Loss: 0.9047\n",
            "Epoch 18/100 - Val Loss: 0.9282\n",
            "Epoch 19/100 - Val Loss: 0.9193\n",
            "Epoch 20/100 - Val Loss: 0.9332\n",
            "Epoch 21/100 - Val Loss: 0.8657\n",
            "Epoch 22/100 - Val Loss: 0.8817\n",
            "Epoch 23/100 - Val Loss: 0.8477\n",
            "Epoch 24/100 - Val Loss: 0.8813\n",
            "Epoch 25/100 - Val Loss: 0.9119\n",
            "Epoch 26/100 - Val Loss: 0.8561\n",
            "Epoch 27/100 - Val Loss: 0.8601\n",
            "Epoch 28/100 - Val Loss: 0.8509\n",
            "Epoch 29/100 - Val Loss: 0.8789\n",
            "Epoch 30/100 - Val Loss: 0.8415\n",
            "Epoch 31/100 - Val Loss: 0.8979\n",
            "Epoch 32/100 - Val Loss: 0.8319\n",
            "Epoch 33/100 - Val Loss: 0.8531\n",
            "Epoch 34/100 - Val Loss: 0.8096\n",
            "Epoch 35/100 - Val Loss: 0.7941\n",
            "Epoch 36/100 - Val Loss: 0.8462\n",
            "Epoch 37/100 - Val Loss: 0.8264\n",
            "Epoch 38/100 - Val Loss: 0.8084\n",
            "Epoch 39/100 - Val Loss: 0.8355\n",
            "Epoch 40/100 - Val Loss: 0.8667\n",
            "Epoch 41/100 - Val Loss: 0.8121\n",
            "Epoch 42/100 - Val Loss: 0.8217\n",
            "Epoch 43/100 - Val Loss: 0.8373\n",
            "Epoch 44/100 - Val Loss: 0.8106\n",
            "Epoch 45/100 - Val Loss: 0.8165\n",
            "Early stopping triggered.\n",
            "Training model 4/10\n",
            "Epoch 1/100 - Val Loss: 1.9432\n",
            "Epoch 2/100 - Val Loss: 1.5536\n",
            "Epoch 3/100 - Val Loss: 1.6075\n",
            "Epoch 4/100 - Val Loss: 1.2375\n",
            "Epoch 5/100 - Val Loss: 1.1935\n",
            "Epoch 6/100 - Val Loss: 1.1638\n",
            "Epoch 7/100 - Val Loss: 1.0728\n",
            "Epoch 8/100 - Val Loss: 1.3090\n",
            "Epoch 9/100 - Val Loss: 1.0761\n",
            "Epoch 10/100 - Val Loss: 1.0377\n",
            "Epoch 11/100 - Val Loss: 1.0683\n",
            "Epoch 12/100 - Val Loss: 0.9682\n",
            "Epoch 13/100 - Val Loss: 0.9055\n",
            "Epoch 14/100 - Val Loss: 0.9459\n",
            "Epoch 15/100 - Val Loss: 0.9248\n",
            "Epoch 16/100 - Val Loss: 1.0602\n",
            "Epoch 17/100 - Val Loss: 0.9286\n",
            "Epoch 18/100 - Val Loss: 0.8870\n",
            "Epoch 19/100 - Val Loss: 0.9399\n",
            "Epoch 20/100 - Val Loss: 0.9029\n",
            "Epoch 21/100 - Val Loss: 0.9668\n",
            "Epoch 22/100 - Val Loss: 0.9294\n",
            "Epoch 23/100 - Val Loss: 0.8811\n",
            "Epoch 24/100 - Val Loss: 0.8937\n",
            "Epoch 25/100 - Val Loss: 0.8898\n",
            "Epoch 26/100 - Val Loss: 0.8972\n",
            "Epoch 27/100 - Val Loss: 0.8792\n",
            "Epoch 28/100 - Val Loss: 0.8691\n",
            "Epoch 29/100 - Val Loss: 0.8479\n",
            "Epoch 30/100 - Val Loss: 0.8402\n",
            "Epoch 31/100 - Val Loss: 0.8440\n",
            "Epoch 32/100 - Val Loss: 0.8187\n",
            "Epoch 33/100 - Val Loss: 0.8365\n",
            "Epoch 34/100 - Val Loss: 0.8682\n",
            "Epoch 35/100 - Val Loss: 0.8392\n",
            "Epoch 36/100 - Val Loss: 0.8015\n",
            "Epoch 37/100 - Val Loss: 0.8227\n",
            "Epoch 38/100 - Val Loss: 0.8770\n",
            "Epoch 39/100 - Val Loss: 0.8442\n",
            "Epoch 40/100 - Val Loss: 0.8322\n",
            "Epoch 41/100 - Val Loss: 0.8224\n",
            "Epoch 42/100 - Val Loss: 0.8063\n",
            "Epoch 43/100 - Val Loss: 0.7924\n",
            "Epoch 44/100 - Val Loss: 0.8189\n",
            "Epoch 45/100 - Val Loss: 0.7987\n",
            "Epoch 46/100 - Val Loss: 0.8018\n",
            "Epoch 47/100 - Val Loss: 0.8075\n",
            "Epoch 48/100 - Val Loss: 0.8348\n",
            "Epoch 49/100 - Val Loss: 0.7529\n",
            "Epoch 50/100 - Val Loss: 0.7985\n",
            "Epoch 51/100 - Val Loss: 0.7775\n",
            "Epoch 52/100 - Val Loss: 0.7771\n",
            "Epoch 53/100 - Val Loss: 0.7604\n",
            "Epoch 54/100 - Val Loss: 0.8079\n",
            "Epoch 55/100 - Val Loss: 0.7709\n",
            "Epoch 56/100 - Val Loss: 0.7587\n",
            "Epoch 57/100 - Val Loss: 0.7639\n",
            "Epoch 58/100 - Val Loss: 0.7865\n",
            "Epoch 59/100 - Val Loss: 0.7534\n",
            "Early stopping triggered.\n",
            "Training model 5/10\n",
            "Epoch 1/100 - Val Loss: 1.7251\n",
            "Epoch 2/100 - Val Loss: 1.5050\n",
            "Epoch 3/100 - Val Loss: 1.3610\n",
            "Epoch 4/100 - Val Loss: 1.2971\n",
            "Epoch 5/100 - Val Loss: 1.1707\n",
            "Epoch 6/100 - Val Loss: 1.0791\n",
            "Epoch 7/100 - Val Loss: 1.0945\n",
            "Epoch 8/100 - Val Loss: 1.1165\n",
            "Epoch 9/100 - Val Loss: 1.1221\n",
            "Epoch 10/100 - Val Loss: 1.0509\n",
            "Epoch 11/100 - Val Loss: 0.9973\n",
            "Epoch 12/100 - Val Loss: 0.9585\n",
            "Epoch 13/100 - Val Loss: 1.0385\n",
            "Epoch 14/100 - Val Loss: 0.9690\n",
            "Epoch 15/100 - Val Loss: 0.9247\n",
            "Epoch 16/100 - Val Loss: 0.9222\n",
            "Epoch 17/100 - Val Loss: 0.9333\n",
            "Epoch 18/100 - Val Loss: 0.9015\n",
            "Epoch 19/100 - Val Loss: 0.9080\n",
            "Epoch 20/100 - Val Loss: 0.9122\n",
            "Epoch 21/100 - Val Loss: 0.8894\n",
            "Epoch 22/100 - Val Loss: 0.9096\n",
            "Epoch 23/100 - Val Loss: 0.8752\n",
            "Epoch 24/100 - Val Loss: 0.9142\n",
            "Epoch 25/100 - Val Loss: 0.8596\n",
            "Epoch 26/100 - Val Loss: 0.9286\n",
            "Epoch 27/100 - Val Loss: 0.8701\n",
            "Epoch 28/100 - Val Loss: 0.8713\n",
            "Epoch 29/100 - Val Loss: 0.8813\n",
            "Epoch 30/100 - Val Loss: 0.8625\n",
            "Epoch 31/100 - Val Loss: 0.8695\n",
            "Epoch 32/100 - Val Loss: 0.8442\n",
            "Epoch 33/100 - Val Loss: 0.8279\n",
            "Epoch 34/100 - Val Loss: 0.8063\n",
            "Epoch 35/100 - Val Loss: 0.8191\n",
            "Epoch 36/100 - Val Loss: 0.8564\n",
            "Epoch 37/100 - Val Loss: 0.8313\n",
            "Epoch 38/100 - Val Loss: 0.8167\n",
            "Epoch 39/100 - Val Loss: 0.8297\n",
            "Epoch 40/100 - Val Loss: 0.8408\n",
            "Epoch 41/100 - Val Loss: 0.8146\n",
            "Epoch 42/100 - Val Loss: 0.8030\n",
            "Epoch 43/100 - Val Loss: 0.7943\n",
            "Epoch 44/100 - Val Loss: 0.7765\n",
            "Epoch 45/100 - Val Loss: 0.8039\n",
            "Epoch 46/100 - Val Loss: 0.7756\n",
            "Epoch 47/100 - Val Loss: 0.8235\n",
            "Epoch 48/100 - Val Loss: 0.8023\n",
            "Epoch 49/100 - Val Loss: 0.7965\n",
            "Epoch 50/100 - Val Loss: 0.7793\n",
            "Epoch 51/100 - Val Loss: 0.8328\n",
            "Epoch 52/100 - Val Loss: 0.7793\n",
            "Epoch 53/100 - Val Loss: 0.7755\n",
            "Epoch 54/100 - Val Loss: 0.7562\n",
            "Epoch 55/100 - Val Loss: 0.7829\n",
            "Epoch 56/100 - Val Loss: 0.7654\n",
            "Epoch 57/100 - Val Loss: 0.7601\n",
            "Epoch 58/100 - Val Loss: 0.7658\n",
            "Epoch 59/100 - Val Loss: 0.7589\n",
            "Epoch 60/100 - Val Loss: 0.7701\n",
            "Epoch 61/100 - Val Loss: 0.7824\n",
            "Epoch 62/100 - Val Loss: 0.7545\n",
            "Epoch 63/100 - Val Loss: 0.7432\n",
            "Epoch 64/100 - Val Loss: 0.7717\n",
            "Epoch 65/100 - Val Loss: 0.7302\n",
            "Epoch 66/100 - Val Loss: 0.7323\n",
            "Epoch 67/100 - Val Loss: 0.7429\n",
            "Epoch 68/100 - Val Loss: 0.7519\n",
            "Epoch 69/100 - Val Loss: 0.7432\n",
            "Epoch 70/100 - Val Loss: 0.7430\n",
            "Epoch 71/100 - Val Loss: 0.7418\n",
            "Epoch 72/100 - Val Loss: 0.7310\n",
            "Epoch 73/100 - Val Loss: 0.7298\n",
            "Epoch 74/100 - Val Loss: 0.7237\n",
            "Epoch 75/100 - Val Loss: 0.7268\n",
            "Epoch 76/100 - Val Loss: 0.7166\n",
            "Epoch 77/100 - Val Loss: 0.7154\n",
            "Epoch 78/100 - Val Loss: 0.7011\n",
            "Epoch 79/100 - Val Loss: 0.7155\n",
            "Epoch 80/100 - Val Loss: 0.7124\n",
            "Epoch 81/100 - Val Loss: 0.7124\n",
            "Epoch 82/100 - Val Loss: 0.6997\n",
            "Epoch 83/100 - Val Loss: 0.6981\n",
            "Epoch 84/100 - Val Loss: 0.6934\n",
            "Epoch 85/100 - Val Loss: 0.6933\n",
            "Epoch 86/100 - Val Loss: 0.7003\n",
            "Epoch 87/100 - Val Loss: 0.6939\n",
            "Epoch 88/100 - Val Loss: 0.6956\n",
            "Epoch 89/100 - Val Loss: 0.6896\n",
            "Epoch 90/100 - Val Loss: 0.6926\n",
            "Epoch 91/100 - Val Loss: 0.6958\n",
            "Epoch 92/100 - Val Loss: 0.6942\n",
            "Epoch 93/100 - Val Loss: 0.6881\n",
            "Epoch 94/100 - Val Loss: 0.6960\n",
            "Epoch 95/100 - Val Loss: 0.6898\n",
            "Epoch 96/100 - Val Loss: 0.6885\n",
            "Epoch 97/100 - Val Loss: 0.6808\n",
            "Epoch 98/100 - Val Loss: 0.6836\n",
            "Epoch 99/100 - Val Loss: 0.6877\n",
            "Epoch 100/100 - Val Loss: 0.6858\n",
            "Training model 6/10\n",
            "Epoch 1/100 - Val Loss: 1.8679\n",
            "Epoch 2/100 - Val Loss: 1.4318\n",
            "Epoch 3/100 - Val Loss: 1.4436\n",
            "Epoch 4/100 - Val Loss: 1.3361\n",
            "Epoch 5/100 - Val Loss: 1.2942\n",
            "Epoch 6/100 - Val Loss: 1.1781\n",
            "Epoch 7/100 - Val Loss: 1.1432\n",
            "Epoch 8/100 - Val Loss: 1.0267\n",
            "Epoch 9/100 - Val Loss: 1.0245\n",
            "Epoch 10/100 - Val Loss: 1.0574\n",
            "Epoch 11/100 - Val Loss: 1.1132\n",
            "Epoch 12/100 - Val Loss: 0.9822\n",
            "Epoch 13/100 - Val Loss: 0.9610\n",
            "Epoch 14/100 - Val Loss: 0.9509\n",
            "Epoch 15/100 - Val Loss: 0.9780\n",
            "Epoch 16/100 - Val Loss: 0.9344\n",
            "Epoch 17/100 - Val Loss: 0.9259\n",
            "Epoch 18/100 - Val Loss: 0.9153\n",
            "Epoch 19/100 - Val Loss: 0.9226\n",
            "Epoch 20/100 - Val Loss: 0.8964\n",
            "Epoch 21/100 - Val Loss: 0.8591\n",
            "Epoch 22/100 - Val Loss: 0.8854\n",
            "Epoch 23/100 - Val Loss: 0.9168\n",
            "Epoch 24/100 - Val Loss: 0.8918\n",
            "Epoch 25/100 - Val Loss: 0.9116\n",
            "Epoch 26/100 - Val Loss: 0.8925\n",
            "Epoch 27/100 - Val Loss: 0.9160\n",
            "Epoch 28/100 - Val Loss: 0.8657\n",
            "Epoch 29/100 - Val Loss: 0.8768\n",
            "Epoch 30/100 - Val Loss: 0.8343\n",
            "Epoch 31/100 - Val Loss: 0.8447\n",
            "Epoch 32/100 - Val Loss: 0.8714\n",
            "Epoch 33/100 - Val Loss: 0.8223\n",
            "Epoch 34/100 - Val Loss: 0.8675\n",
            "Epoch 35/100 - Val Loss: 0.8540\n",
            "Epoch 36/100 - Val Loss: 0.8565\n",
            "Epoch 37/100 - Val Loss: 0.8213\n",
            "Epoch 38/100 - Val Loss: 0.9120\n",
            "Epoch 39/100 - Val Loss: 0.8703\n",
            "Epoch 40/100 - Val Loss: 0.8352\n",
            "Epoch 41/100 - Val Loss: 0.8233\n",
            "Epoch 42/100 - Val Loss: 0.8550\n",
            "Epoch 43/100 - Val Loss: 0.8252\n",
            "Early stopping triggered.\n",
            "Training model 7/10\n",
            "Epoch 1/100 - Val Loss: 1.7613\n",
            "Epoch 2/100 - Val Loss: 1.4828\n",
            "Epoch 3/100 - Val Loss: 1.3582\n",
            "Epoch 4/100 - Val Loss: 1.2882\n",
            "Epoch 5/100 - Val Loss: 1.2092\n",
            "Epoch 6/100 - Val Loss: 1.1872\n",
            "Epoch 7/100 - Val Loss: 1.0923\n",
            "Epoch 8/100 - Val Loss: 1.1084\n",
            "Epoch 9/100 - Val Loss: 1.0142\n",
            "Epoch 10/100 - Val Loss: 1.0456\n",
            "Epoch 11/100 - Val Loss: 0.9997\n",
            "Epoch 12/100 - Val Loss: 1.0229\n",
            "Epoch 13/100 - Val Loss: 0.9607\n",
            "Epoch 14/100 - Val Loss: 1.0402\n",
            "Epoch 15/100 - Val Loss: 0.9662\n",
            "Epoch 16/100 - Val Loss: 0.9960\n",
            "Epoch 17/100 - Val Loss: 0.9289\n",
            "Epoch 18/100 - Val Loss: 0.9618\n",
            "Epoch 19/100 - Val Loss: 0.9656\n",
            "Epoch 20/100 - Val Loss: 0.8847\n",
            "Epoch 21/100 - Val Loss: 0.9371\n",
            "Epoch 22/100 - Val Loss: 0.9200\n",
            "Epoch 23/100 - Val Loss: 0.8983\n",
            "Epoch 24/100 - Val Loss: 0.8786\n",
            "Epoch 25/100 - Val Loss: 0.8465\n",
            "Epoch 26/100 - Val Loss: 0.8632\n",
            "Epoch 27/100 - Val Loss: 0.8676\n",
            "Epoch 28/100 - Val Loss: 0.8466\n",
            "Epoch 29/100 - Val Loss: 0.9089\n",
            "Epoch 30/100 - Val Loss: 0.8669\n",
            "Epoch 31/100 - Val Loss: 0.8896\n",
            "Epoch 32/100 - Val Loss: 0.8563\n",
            "Epoch 33/100 - Val Loss: 0.8462\n",
            "Epoch 34/100 - Val Loss: 0.8761\n",
            "Epoch 35/100 - Val Loss: 0.8552\n",
            "Early stopping triggered.\n",
            "Training model 8/10\n",
            "Epoch 1/100 - Val Loss: 1.8784\n",
            "Epoch 2/100 - Val Loss: 1.4641\n",
            "Epoch 3/100 - Val Loss: 1.8654\n",
            "Epoch 4/100 - Val Loss: 1.3016\n",
            "Epoch 5/100 - Val Loss: 1.3084\n",
            "Epoch 6/100 - Val Loss: 1.1284\n",
            "Epoch 7/100 - Val Loss: 1.1424\n",
            "Epoch 8/100 - Val Loss: 1.0451\n",
            "Epoch 9/100 - Val Loss: 1.0383\n",
            "Epoch 10/100 - Val Loss: 1.0354\n",
            "Epoch 11/100 - Val Loss: 1.0536\n",
            "Epoch 12/100 - Val Loss: 1.0192\n",
            "Epoch 13/100 - Val Loss: 1.0056\n",
            "Epoch 14/100 - Val Loss: 1.1141\n",
            "Epoch 15/100 - Val Loss: 1.0060\n",
            "Epoch 16/100 - Val Loss: 1.0450\n",
            "Epoch 17/100 - Val Loss: 0.8978\n",
            "Epoch 18/100 - Val Loss: 0.9528\n",
            "Epoch 19/100 - Val Loss: 0.9229\n",
            "Epoch 20/100 - Val Loss: 0.8712\n",
            "Epoch 21/100 - Val Loss: 0.9290\n",
            "Epoch 22/100 - Val Loss: 0.9580\n",
            "Epoch 23/100 - Val Loss: 0.9180\n",
            "Epoch 24/100 - Val Loss: 0.9641\n",
            "Epoch 25/100 - Val Loss: 0.8976\n",
            "Epoch 26/100 - Val Loss: 0.8814\n",
            "Epoch 27/100 - Val Loss: 0.8852\n",
            "Epoch 28/100 - Val Loss: 0.8934\n",
            "Epoch 29/100 - Val Loss: 0.8815\n",
            "Epoch 30/100 - Val Loss: 0.8756\n",
            "Early stopping triggered.\n",
            "Training model 9/10\n",
            "Epoch 1/100 - Val Loss: 1.7794\n",
            "Epoch 2/100 - Val Loss: 1.4206\n",
            "Epoch 3/100 - Val Loss: 1.3195\n",
            "Epoch 4/100 - Val Loss: 1.2557\n",
            "Epoch 5/100 - Val Loss: 1.1606\n",
            "Epoch 6/100 - Val Loss: 1.1009\n",
            "Epoch 7/100 - Val Loss: 1.0675\n",
            "Epoch 8/100 - Val Loss: 1.0649\n",
            "Epoch 9/100 - Val Loss: 1.1725\n",
            "Epoch 10/100 - Val Loss: 0.9827\n",
            "Epoch 11/100 - Val Loss: 1.0572\n",
            "Epoch 12/100 - Val Loss: 0.9695\n",
            "Epoch 13/100 - Val Loss: 0.9529\n",
            "Epoch 14/100 - Val Loss: 0.9426\n",
            "Epoch 15/100 - Val Loss: 1.0213\n",
            "Epoch 16/100 - Val Loss: 0.9160\n",
            "Epoch 17/100 - Val Loss: 0.9398\n",
            "Epoch 18/100 - Val Loss: 0.9151\n",
            "Epoch 19/100 - Val Loss: 0.8765\n",
            "Epoch 20/100 - Val Loss: 0.9048\n",
            "Epoch 21/100 - Val Loss: 0.9221\n",
            "Epoch 22/100 - Val Loss: 0.8612\n",
            "Epoch 23/100 - Val Loss: 0.8575\n",
            "Epoch 24/100 - Val Loss: 0.8451\n",
            "Epoch 25/100 - Val Loss: 0.8819\n",
            "Epoch 26/100 - Val Loss: 0.8473\n",
            "Epoch 27/100 - Val Loss: 0.9126\n",
            "Epoch 28/100 - Val Loss: 0.8298\n",
            "Epoch 29/100 - Val Loss: 0.8601\n",
            "Epoch 30/100 - Val Loss: 0.8330\n",
            "Epoch 31/100 - Val Loss: 0.8540\n",
            "Epoch 32/100 - Val Loss: 0.8787\n",
            "Epoch 33/100 - Val Loss: 0.8325\n",
            "Epoch 34/100 - Val Loss: 0.8266\n",
            "Epoch 35/100 - Val Loss: 0.8409\n",
            "Epoch 36/100 - Val Loss: 0.8001\n",
            "Epoch 37/100 - Val Loss: 0.7878\n",
            "Epoch 38/100 - Val Loss: 0.8178\n",
            "Epoch 39/100 - Val Loss: 0.7795\n",
            "Epoch 40/100 - Val Loss: 0.7903\n",
            "Epoch 41/100 - Val Loss: 0.7918\n",
            "Epoch 42/100 - Val Loss: 0.7897\n",
            "Epoch 43/100 - Val Loss: 0.8075\n",
            "Epoch 44/100 - Val Loss: 0.7857\n",
            "Epoch 45/100 - Val Loss: 0.8077\n",
            "Epoch 46/100 - Val Loss: 0.7657\n",
            "Epoch 47/100 - Val Loss: 0.8491\n",
            "Epoch 48/100 - Val Loss: 0.7789\n",
            "Epoch 49/100 - Val Loss: 0.7916\n",
            "Epoch 50/100 - Val Loss: 0.7599\n",
            "Epoch 51/100 - Val Loss: 0.7734\n",
            "Epoch 52/100 - Val Loss: 0.7770\n",
            "Epoch 53/100 - Val Loss: 0.7680\n",
            "Epoch 54/100 - Val Loss: 0.7656\n",
            "Epoch 55/100 - Val Loss: 0.7670\n",
            "Epoch 56/100 - Val Loss: 0.7571\n",
            "Epoch 57/100 - Val Loss: 0.7731\n",
            "Epoch 58/100 - Val Loss: 0.7698\n",
            "Epoch 59/100 - Val Loss: 0.7468\n",
            "Epoch 60/100 - Val Loss: 0.7508\n",
            "Epoch 61/100 - Val Loss: 0.7490\n",
            "Epoch 62/100 - Val Loss: 0.7408\n",
            "Epoch 63/100 - Val Loss: 0.7607\n",
            "Epoch 64/100 - Val Loss: 0.7749\n",
            "Epoch 65/100 - Val Loss: 0.7298\n",
            "Epoch 66/100 - Val Loss: 0.7403\n",
            "Epoch 67/100 - Val Loss: 0.7271\n",
            "Epoch 68/100 - Val Loss: 0.7250\n",
            "Epoch 69/100 - Val Loss: 0.7240\n",
            "Epoch 70/100 - Val Loss: 0.7215\n",
            "Epoch 71/100 - Val Loss: 0.7197\n",
            "Epoch 72/100 - Val Loss: 0.7331\n",
            "Epoch 73/100 - Val Loss: 0.7048\n",
            "Epoch 74/100 - Val Loss: 0.7057\n",
            "Epoch 75/100 - Val Loss: 0.7107\n",
            "Epoch 76/100 - Val Loss: 0.7090\n",
            "Epoch 77/100 - Val Loss: 0.7109\n",
            "Epoch 78/100 - Val Loss: 0.7033\n",
            "Epoch 79/100 - Val Loss: 0.7023\n",
            "Epoch 80/100 - Val Loss: 0.7081\n",
            "Epoch 81/100 - Val Loss: 0.6953\n",
            "Epoch 82/100 - Val Loss: 0.7002\n",
            "Epoch 83/100 - Val Loss: 0.6928\n",
            "Epoch 84/100 - Val Loss: 0.6798\n",
            "Epoch 85/100 - Val Loss: 0.6817\n",
            "Epoch 86/100 - Val Loss: 0.6877\n",
            "Epoch 87/100 - Val Loss: 0.6940\n",
            "Epoch 88/100 - Val Loss: 0.6952\n",
            "Epoch 89/100 - Val Loss: 0.6823\n",
            "Epoch 90/100 - Val Loss: 0.6769\n",
            "Epoch 91/100 - Val Loss: 0.6977\n",
            "Epoch 92/100 - Val Loss: 0.6697\n",
            "Epoch 93/100 - Val Loss: 0.6738\n",
            "Epoch 94/100 - Val Loss: 0.6867\n",
            "Epoch 95/100 - Val Loss: 0.6784\n",
            "Epoch 96/100 - Val Loss: 0.6782\n",
            "Epoch 97/100 - Val Loss: 0.6834\n",
            "Epoch 98/100 - Val Loss: 0.6778\n",
            "Epoch 99/100 - Val Loss: 0.6783\n",
            "Epoch 100/100 - Val Loss: 0.6825\n",
            "Training model 10/10\n",
            "Epoch 1/100 - Val Loss: 1.7112\n",
            "Epoch 2/100 - Val Loss: 1.4986\n",
            "Epoch 3/100 - Val Loss: 1.6201\n",
            "Epoch 4/100 - Val Loss: 1.2436\n",
            "Epoch 5/100 - Val Loss: 1.2447\n",
            "Epoch 6/100 - Val Loss: 1.1743\n",
            "Epoch 7/100 - Val Loss: 1.1951\n",
            "Epoch 8/100 - Val Loss: 1.1020\n",
            "Epoch 9/100 - Val Loss: 0.9860\n",
            "Epoch 10/100 - Val Loss: 1.0173\n",
            "Epoch 11/100 - Val Loss: 1.0088\n",
            "Epoch 12/100 - Val Loss: 1.0276\n",
            "Epoch 13/100 - Val Loss: 0.9695\n",
            "Epoch 14/100 - Val Loss: 1.0703\n",
            "Epoch 15/100 - Val Loss: 0.9333\n",
            "Epoch 16/100 - Val Loss: 0.9042\n",
            "Epoch 17/100 - Val Loss: 0.8731\n",
            "Epoch 18/100 - Val Loss: 0.9633\n",
            "Epoch 19/100 - Val Loss: 0.9227\n",
            "Epoch 20/100 - Val Loss: 0.8714\n",
            "Epoch 21/100 - Val Loss: 0.9328\n",
            "Epoch 22/100 - Val Loss: 0.8766\n",
            "Epoch 23/100 - Val Loss: 0.8742\n",
            "Epoch 24/100 - Val Loss: 0.8820\n",
            "Epoch 25/100 - Val Loss: 0.8698\n",
            "Epoch 26/100 - Val Loss: 0.8739\n",
            "Epoch 27/100 - Val Loss: 0.8932\n",
            "Epoch 28/100 - Val Loss: 0.8479\n",
            "Epoch 29/100 - Val Loss: 0.9069\n",
            "Epoch 30/100 - Val Loss: 0.8527\n",
            "Epoch 31/100 - Val Loss: 0.8345\n",
            "Epoch 32/100 - Val Loss: 0.8392\n",
            "Epoch 33/100 - Val Loss: 0.8400\n",
            "Epoch 34/100 - Val Loss: 0.8116\n",
            "Epoch 35/100 - Val Loss: 0.8527\n",
            "Epoch 36/100 - Val Loss: 0.8204\n",
            "Epoch 37/100 - Val Loss: 0.8356\n",
            "Epoch 38/100 - Val Loss: 0.8238\n",
            "Epoch 39/100 - Val Loss: 0.8127\n",
            "Epoch 40/100 - Val Loss: 0.7983\n",
            "Epoch 41/100 - Val Loss: 0.7897\n",
            "Epoch 42/100 - Val Loss: 0.7919\n",
            "Epoch 43/100 - Val Loss: 0.8066\n",
            "Epoch 44/100 - Val Loss: 0.7725\n",
            "Epoch 45/100 - Val Loss: 0.8042\n",
            "Epoch 46/100 - Val Loss: 0.7967\n",
            "Epoch 47/100 - Val Loss: 0.7941\n",
            "Epoch 48/100 - Val Loss: 0.7890\n",
            "Epoch 49/100 - Val Loss: 0.8219\n",
            "Epoch 50/100 - Val Loss: 0.7791\n",
            "Epoch 51/100 - Val Loss: 0.8337\n",
            "Epoch 52/100 - Val Loss: 0.8016\n",
            "Epoch 53/100 - Val Loss: 0.7756\n",
            "Epoch 54/100 - Val Loss: 0.7741\n",
            "Early stopping triggered.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_ensemble(loader):\n",
        "    predictions = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, _ in loader:\n",
        "            inputs = inputs.to(device)\n",
        "            outputs = sum(model(inputs) for model in ensemble) / num_models\n",
        "            predictions.append(outputs.cpu())\n",
        "    return torch.cat(predictions)"
      ],
      "metadata": {
        "id": "QqNoTrZZczPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = evaluate_ensemble(DataLoader(testset, batch_size*2))\n",
        "acc = (preds.argmax(1) == torch.tensor(testset.targets)).float().mean()\n",
        "print(f\"Ensemble Accuracy: {acc.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf2dYa0Wc2Jf",
        "outputId": "622209ac-956d-4833-bf0c-b998d43f9581"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ensemble Accuracy: 0.9509\n"
          ]
        }
      ]
    }
  ]
}